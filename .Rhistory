GRIDFILES<-wd
INDEX<-1
gridf<-GRIDFILES[INDEX]
head(wd)
summary(wd)
# create a field for depth bin
wd$DEPTH_BIN<-"MISSING"
wd[is.na(wd$Bty_Mean),]$DEPTH_BIN<-"UNKN"
# label depth ranges on mean bathy value
wd[which(wd$Bty_Mean > -1),]$DEPTH_BIN<-"ONEM" # not samplable
wd[which(wd$Bty_Mean >= -6 & wd$Bty_Mean < -1),]$DEPTH_BIN<-"SHAL"
wd[which(wd$Bty_Mean >= -18 & wd$Bty_Mean < -6),]$DEPTH_BIN<-"MIDD"
wd[which(wd$Bty_Mean >= -30 & wd$Bty_Mean < -18),]$DEPTH_BIN<-"DEEP"
wd[which(wd$Bty_Mean < -30),]$DEPTH_BIN<-"MESO"
# not all grids have this, but some have values of 1
wd[which(wd$Bty_Mean >= 0),]$DEPTH_BIN<-"LAND"
table(wd$DEPTH_BIN, wd$Hard_Per)
if("Hard_Per" %in% colnames(wd)){
#Change hard and soft and unknown per to be proportion of not land
if("Hard_Per" %in% colnames(wd)){
nl<-which(wd$Land_Per<100)
wd$NOT_LAND<-(100-wd$Land_Per)/100
wd[nl, c("Hard_Per", "Unk_Per", "Soft_Per")]<-wd[nl, c("Hard_Per", "Unk_Per", "Soft_Per")]/wd[nl, ]$NOT_LAND
}
# create fields for hard soft
wd$HARD_50<-wd$HARD_10<-"MISSING"
## HARD_1O set to "H" if hard >= 10%, otherwise set to whatever is higher of soft or unknown
table(wd$Hard_Per)
h<-which(wd$Hard_Per>=10); 	if (length(h)>0)	 	wd[h,]$HARD_10<-"H"
s<-which(wd$HARD_10=="MISSING" & wd$Soft_Per>=wd$Unk_Per); 	if (length(s)>0)		 	wd[s,]$HARD_10<-"S"
u<-which(wd$HARD_10=="MISSING" & wd$Unk_Per>wd$Soft_Per); 	if (length(u)>0)	 		wd[u,]$HARD_10<-"U"
table(wd$HARD_10)
## HARD_50 sets to Unknown if > 50% Unkown .. otherwise set to majority of hard/soft
u<-which(wd$Unk_Per>50); 	if (length(u)>0)	 	wd[u,]$HARD_50<-"U"
s<-which(wd$HARD_50=="MISSING" & wd$Soft_Per>wd$Hard_Per); 	if (length(s)>0)	 	wd[s,]$HARD_50<-"S"
h<-which(wd$HARD_50=="MISSING" & wd$Hard_Per>=wd$Soft_Per); 	if (length(h)>0)	 	wd[h,]$HARD_50<-"H"
table(wd$HARD_50)
} else {
# No hard/soft information
wd$HARD_10<-wd$HARD_50<-"U"
}
# add reef zone field - whatever is largest
if(INDEX %in% c(101, 108, 109, 110)){
wd$ZONE_CODE<-"FRF"
} else {
RZ_NAMES<-c("RZ_FRF_Per", "RZ_BRF_Per", "RZ_LAG_Per", "RZ_RCF_Per", "RZ_PRS_Per", "RZ_LND_Per", "RZ_UNK_Per")
wd$MAX_POS<-apply(wd[,RZ_NAMES],1,which.max)
RZONES<-c("FRF", "BRF", "LAG", "RCF", "PRS", "LND", "UNK")
wd$ZONE_CODE<-as.factor(wd$MAX_POS)
levels(wd$ZONE_CODE)<-RZONES[sort(unique(wd$MAX_POS))]
table(wd$ZONE_CODE, wd$MAX_POS)
wd$MAX_POS<-NULL
}
wd$ZONE_CODE<-"FRF"
RZ_NAMES<-c("RZ_FRF_Per", "RZ_BRF_Per", "RZ_LAG_Per", "RZ_RCF_Per", "RZ_PRS_Per", "RZ_LND_Per", "RZ_UNK_Per")
wd$MAX_POS<-apply(wd[,RZ_NAMES],1,which.max)
summary(wd$RZ_FRF_Per)
library(dplyr)
wd$MAX_POS<-apply(wd[,RZ_NAMES],MARGIN=1,which.max)
RZ_NAMES<-c("RZ_FRF_Per", "RZ_BRF_Per", "RZ_LAG_Per", "RZ_RCF_Per", "RZ_PRS_Per", "RZ_LND_Per", "RZ_UNK_Per")
wd$MAX_POS<-apply(wd[,RZ_NAMES],MARGIN=1,which.max)
if(wd$RZ_FRF_Per == 100){
#INDEX %in% c(101, 108, 109, 110)){
wd$ZONE_CODE<-"FRF"
} else {
RZ_NAMES<-c("RZ_FRF_Per", "RZ_BRF_Per", "RZ_LAG_Per", "RZ_RCF_Per", "RZ_PRS_Per", "RZ_LND_Per", "RZ_UNK_Per")
wd$MAX_POS<-apply(wd[,RZ_NAMES],1,which.max)
RZONES<-c("FRF", "BRF", "LAG", "RCF", "PRS", "LND", "UNK")
wd$ZONE_CODE<-as.factor(wd$MAX_POS)
levels(wd$ZONE_CODE)<-RZONES[sort(unique(wd$MAX_POS))]
table(wd$ZONE_CODE, wd$MAX_POS)
wd$MAX_POS<-NULL
}
head(wd,1)
wd[,wd$RZ_RCF_Per == 90]
wd[,"RZ_RCF_Per" == 90]
wd["RZ_RCF_Per" == 90,]
summary(wd$RZ_RCF_Per)
summary(wd$ZONE_CODE)
unique(wd$ZONE_CODE)
RZ_NAMES<-c("RZ_FRF_Per", "RZ_BRF_Per", "RZ_LAG_Per", "RZ_RCF_Per", "RZ_PRS_Per", "RZ_LND_Per", "RZ_UNK_Per")
wd$MAX_POS<-apply(wd[,RZ_NAMES],1,which.max)
rm(list=ls())
library(gdata)             # needed for drop_levels()
library(reshape)           # reshape library inclues the cast() function used below
rm(list=ls())
library(gdata)             # needed for drop_levels()
library(reshape)           # reshape library inclues the cast() function used below
# set working directory to fish-paste
setwd("D:/CRED/fish_team_R/fish-paste")
#LOAD LIBRARY FUNCTIONS ...
source("lib/core_functions.R")
source("lib/fish_team_functions.R")
#source("lib/Islandwide Mean&Variance Functions.R")
# get strata and sectors data data - NB - the data in the raw file should be checked and updated
sectors<-read.csv("data/Sectors-Strata-Areas.csv", stringsAsFactors=FALSE)
# load site master to merge with sector names
sm<-read.csv("data/SURVEY MASTER.csv")
sm$SITE<-SiteNumLeadingZeros(sm$SITE)
## LOAD AND CLEAN fish data
load("data/ALL_REA_FISH_RAW.rdata")
x<-df
DATA_COLS<-c("SITEVISITID", "METHOD", "DATE_", "OBS_YEAR",  "SITE", "REEF_ZONE",  "DEPTH_BIN",  "ISLAND", "LATITUDE",  "LONGITUDE",  "REGION" , "REGION_NAME", "SECTOR", "SPECIAL_AREA", "EXCLUDE_FLAG", "TRAINING_YN",
"REP",  "REPLICATEID", "DIVER", "HABITAT_CODE", "DEPTH",
"HARD_CORAL", "MA",  "TA",  "CCA",  "SAND",  "SOFT_CORAL", "CLAM" , "SPONGE", "CORALLIMORPH", "CYANO", "TUNICATE", "ZOANTHID" , "OTHER", "OTHER_TYPE",
"SPECIES", "COUNT", "SIZE_", "OBS_TYPE",
"COMPLEXITY", "SUBSTRATE_HEIGHT_0", "SUBSTRATE_HEIGHT_20", "SUBSTRATE_HEIGHT_50", "SUBSTRATE_HEIGHT_100", "SUBSTRATE_HEIGHT_150", "MAX_HEIGHT", "VISIBILITY",
"SCIENTIFIC_NAME",  "TAXONNAME", "COMMONNAME", "GENUS", "FAMILY" , "COMMONFAMILYALL", "LMAX", "LW_A",  "LW_B",  "LENGTH_CONVERSION_FACTOR", "TROPHIC", "TROPHIC_MONREP")
head(x[,DATA_COLS])
x<-x[,DATA_COLS]
x$SITE<-SiteNumLeadingZeros(x$SITE)
x[is.na(x$TRAINING_YN),]$TRAINING_YN<-FALSE   # Training flag of NA is equivalent to a FALSE .. as none of the older data was 'training data'
x<-subset(x, x$TRAINING_YN==FALSE)
x<-subset(x, x$EXCLUDE_FLAG==0, drop=TRUE)
x<-subset(x, x$METHOD %in% c("nSPC", "nSPC-CCR"), drop=TRUE)
#x<-subset(x, x$OBS_YEAR >2008, drop=TRUE)
x<-subset(x, x$OBS_TYPE %in% c("U","I","N", "F", "T", "P"))  # note this includes all the data .. wlll need to add filtering to the scripts that analyse the data
#add SURVEY MASTER information to x
x<-merge(x, sm[,c("SITEVISITID", "SEC_NAME", "ANALYSIS_YEAR", "ANALYSIS_SCHEME")], by=c("SITEVISITID"), all.x=TRUE)
#CHECK THAT all ANALYSIS_SCHEMES are present in the site_master file)
idw<-x[is.na(x$ANALYSIS_SCHEME)  & x$METHOD=="nSPC", c("REGION", "SITE","OBS_YEAR", "METHOD"),]
if(dim(idw)[1]>0) {cat("nSPC sites with MISSING ANALYSIS_SCHEME")}   # should be 0
sh_out<-CalcMeanSHMeanSHDiff(x)
x$MEAN_SH<-sh_out[[1]]
x$SD_SH_DIFF<-sh_out[[3]]
# remove the component SUBSTRATE_HEIGHT fields
x<-x[, setdiff(names(x),c("SUBSTRATE_HEIGHT_0", "SUBSTRATE_HEIGHT_20", "SUBSTRATE_HEIGHT_50", "SUBSTRATE_HEIGHT_100", "SUBSTRATE_HEIGHT_150"))]
############################################################################################
x<-droplevels(x)
x$COMPLEXITY<-as.vector(toupper(x$COMPLEXITY))
x[is.na(x$COMPLEXITY),"COMPLEXITY"]<-"UNKNOWN"
COMPLEXITY_VALUES<-toupper(c("Low", "Med-Low", "Med", "Med-Hi", "Hi", "Very-Hi"))
x$ComplexityValue<-NaN
for (i in 1:length(COMPLEXITY_VALUES)){
if(COMPLEXITY_VALUES[i] %in% x$COMPLEXITY){
x[x$COMPLEXITY==COMPLEXITY_VALUES[i],]$ComplexityValue<-i
}
}
#######################
tmp.lev<-levels(x$HABITAT_CODE); head(tmp.lev)
levels(x$HABITAT_CODE)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$SCIENTIFIC_NAME); head(tmp.lev)
levels(x$SCIENTIFIC_NAME)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$COMMONNAME); head(tmp.lev)
levels(x$COMMONNAME)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$GENUS); head(tmp.lev)
levels(x$GENUS)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$FAMILY); head(tmp.lev)
levels(x$FAMILY)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$COMMONFAMILYALL); head(tmp.lev)
levels(x$COMMONFAMILYALL)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$TROPHIC_MONREP); head(tmp.lev)
levels(x$TROPHIC_MONREP)<-c(tmp.lev, "UNKNOWN")
x[is.na(x$HABITAT_CODE),"HABITAT_CODE"]<-"UNKNOWN"
x[is.na(x$SCIENTIFIC_NAME),"SCIENTIFIC_NAME"]<-"UNKNOWN"
x[is.na(x$COMMONNAME),"COMMONNAME"]<-"UNKNOWN"
x[is.na(x$GENUS),"GENUS"]<-"UNKNOWN"
x[is.na(x$FAMILY),"FAMILY"]<-"UNKNOWN"
x[is.na(x$COMMONFAMILYALL),"COMMONFAMILYALL"]<-"UNKNOWN"
x[is.na(x$TROPHIC_MONREP),"TROPHIC_MONREP"]<-"UNKNOWN"
x[is.na(x$COUNT),]$COUNT<-0
x[is.na(x$SIZE_),]$SIZE_<-0
###x[is.na(x$LMAX),]$LMAX<-999
## separate out the north and south marianas
levels(x$REGION)<-c(levels(x$REGION), "S.MARIAN", "N.MARIAN")
x[x$ISLAND %in% c("Guam", "Rota", "Aguijan", "Tinian", "Saipan"),]$REGION<-"S.MARIAN"
x[x$ISLAND %in% c("Alamagan","Guguan","Sarigan","Pagan", "Agrihan", "Asuncion", "Maug", "Farallon de Pajaros"),]$REGION<-"N.MARIAN"
sectors[sectors$ISLAND %in% c("Guam", "Rota", "Aguijan", "Tinian", "Saipan"),]$REGION<-"S.MARIAN"
sectors[sectors$ISLAND %in% c("Alamagan","Guguan","Sarigan","Pagan", "Agrihan", "Asuncion", "Maug", "Farallon de Pajaros"),]$REGION<-"N.MARIAN"
sectors<-droplevels(sectors)
###NEED TO SET VISIBILITY to -9999 when its NA
### NOTE THAT NWHI 2012 has VISIBLITY OF NA
unique(x[is.na(x$VISIBILITY),c("REGION", "OBS_YEAR")])
x[is.na(x$VISIBILITY),]$VISIBILITY<- -999
x[x$SITE=="GUA-01310",]$LATITUDE<-13.24173
x[x$SITE=="GUA-01310",]$LONGITUDE<-144.70428
x<-droplevels(x)
#BENTHOS DOES NOT ALWAYS SUM TO 100% .. THIS IS A (LONG-LIVED!) TEMP FIX .. PROBABLY BETTER TO FIX THIS INSIDE ORACLE
BENTHIC_FIELDS<-c("HARD_CORAL", "SOFT_CORAL", "MA", "CCA", "TA", "SAND", "CYANO", "CLAM", "CORALLIMORPH", "ZOANTHID", "TUNICATE", "SPONGE", "OTHER")
UNIQUE_ROUND<-c("REGION", "OBS_YEAR", "METHOD")
round_table<-Aggregate_InputTable(x, UNIQUE_ROUND)
x$countBD<-apply(x[,BENTHIC_FIELDS], 1, function(xx) length(which(!is.na(xx))))  #IDW 10-22-2013 checking for situation where there is NO benthic data at all
for(i in 1:dim(round_table)[1])
{
if(round_table[i,"METHOD"] %in% c("nSPC", "nSPC-CCR"))
{
tmp_data<-x[x$OBS_YEAR==round_table[i,"OBS_YEAR"] & x$METHOD==round_table[i,"METHOD"] & x$REGION==round_table[i,"REGION"],]
#go through BENTHIC_FIELDS, checking whether there are some NAs and some data values
for(j in 1:length(BENTHIC_FIELDS))
{
## IF there are both non NAs and NAs
if(length(tmp_data[!is.na(tmp_data[,BENTHIC_FIELDS[j]]),BENTHIC_FIELDS[j]]) > 0
& length(tmp_data[is.na(tmp_data[,BENTHIC_FIELDS[j]]),BENTHIC_FIELDS[j]]) > 0)
{
#set all NAs of that field to 0
tmp_data[is.na(tmp_data[,BENTHIC_FIELDS[j]]),BENTHIC_FIELDS[j]]<-0
#now rewrite the benthic fields with NAs converted to zeros
x[x$OBS_YEAR==round_table[i,"OBS_YEAR"] & x$METHOD==round_table[i,"METHOD"] & x$REGION==round_table[i,"REGION"],BENTHIC_FIELDS[j]]<-tmp_data[,BENTHIC_FIELDS[j]]
}
}
}
}
# now reset zeros to NAs for all records where there was NO benthic data at all
x[x$countBD==0,BENTHIC_FIELDS]<-NA
wd<-droplevels(x)
wd[!wd$OBS_TYPE %in% c("U", "I", "N"), ]$COUNT<-0
wd<-subset(wd, wd$METHOD %in% c("nSPC"))
wd<-droplevels(wd)
#base information about the survey - field names should match those in input file (obviously!)
UNIQUE_SURVEY<-c("SITEVISITID","METHOD")
UNIQUE_REP<-c(UNIQUE_SURVEY, "REP")
UNIQUE_COUNT<-c(UNIQUE_REP, "REPLICATEID")
#get base survey info, calculate average depth+complexity+so on
SURVEY_INFO<-c("OBS_YEAR", "REGION", "REGION_NAME", "ISLAND", "ANALYSIS_SCHEME", "ANALYSIS_YEAR", "SEC_NAME", "SITE", "DATE_", "REEF_ZONE", "DEPTH_BIN", "LATITUDE", "LONGITUDE", "SITEVISITID", "METHOD")
survey_table<-Aggregate_InputTable(wd, SURVEY_INFO)
OTHER_BENTHIC<-c("CLAM", "CORALLIMORPH", "ZOANTHID", "TUNICATE", "SPONGE", "TA", "CYANO", "OTHER", "SOFT_CORAL")
wd$OTHER_BENTHIC<-rowSums(wd[,OTHER_BENTHIC],na.rm=T)
SURVEY_SITE_DATA<-c("DEPTH", "HARD_CORAL", "MA", "CCA", "SAND", "OTHER_BENTHIC", "ComplexityValue", "MEAN_SH", "SD_SH_DIFF", "MAX_HEIGHT")
# Generate a data frame with all benthic and site level information for each survey
survey_est_benthos<-Calc_Site_nSurveysArea(wd, UNIQUE_SURVEY, UNIQUE_REP, UNIQUE_COUNT, SURVEY_SITE_DATA)   #Calc_Site_nSurveysArea deals better with situations where one REP has benthic data and other doesnt.
surveys<-merge(survey_table, survey_est_benthos, by=UNIQUE_SURVEY)
#Pull all species information into a separate df, for possible later use ..
FISH_SPECIES_FIELDS<-c("SPECIES","TAXONNAME", "FAMILY", "COMMONFAMILYALL", "TROPHIC_MONREP", "LW_A", "LW_B", "LENGTH_CONVERSION_FACTOR")
species_table<-Aggregate_InputTable(wd, FISH_SPECIES_FIELDS)
# GENERATE SUMMARY METRICS --------------------------------------------------
#r1<-Calc_Site_Bio(wd, "TROPHIC_MONREP"); trophic.cols<-names(r1[3:dim(r1)[2]])
#r2a<-Calc_Site_Abund(wd, "SPECIES"); species.cols<-levels(species_table$SPECIES)
r2b<-Calc_Site_Bio(wd, "SPECIES"); species.cols<-levels(species_table$SPECIES)
#r3<-Calc_Site_Bio_By_SizeClass(wd, c(0,20,50,Inf)); size.cols<-names(r4b)[3:dim(r4b)[2]]
#r4<-Modified_Site_Species_Richness(wd)
# to calculate mean fish length per site
#r5<-Calc_Site_MeanLength(wd,min_size=0.4)
r6<-Calc_Site_Bio(wd,"FAMILY"); family.cols<-names(r6[3:dim(r6)[2]])
# filter data for APVI, LUBO, stingrays = Dasyatidae
r2ba<-r2b[,c("APVI","LUBO")]
r6a<-r6[,"Dasyatidae"]
r6a<-r6[,c("Dasyatidae")]
colnames(r6)
head(r2ba)
r6a<-as.data.frame(r6[,c("Dasyatidae")])
#Merge Site Data and Count Data Per Site Per Grouping Variable (e.g. Species, Tropic_MonRep, Family)
wsd<-merge(surveys,r2b,by=UNIQUE_SURVEY)
wsd$TotFish<-rowSums(wsd[,species.cols])
View(wsd)
#Merge Site Data and Count Data Per Site Per Grouping Variable (e.g. Species, Tropic_MonRep, Family)
wsd<-merge(surveys,r2b,by=UNIQUE_SURVEY)
#Merge Site Data and Count Data Per Site Per Grouping Variable (e.g. Species, Tropic_MonRep, Family)
wsd<-merge(surveys,r2ba,by=UNIQUE_SURVEY)
#Merge Site Data and Count Data Per Site Per Grouping Variable (e.g. Species, Tropic_MonRep, Family)
wsd<-merge(surveys,r2b,by=UNIQUE_SURVEY)
wsd$TotFish<-rowSums(wsd[,species.cols])
data.cols<-c(species.cols, "TotFish", SURVEY_SITE_DATA)
wsd<-merge(wsd, r6, by=UNIQUE_SURVEY)
data.cols<-c(data.cols, family.cols)
colnames(wsd)
# filter data for APVI, LUBO, stingrays = Dasyatidae
wsda<-wsd[,c("SITEVISITID","METHOD","OBS_YEAR","REGION","REGION_NAME","ISLAND","ANALYSIS_SCHEME","ANALYSIS_YEAR","SEC_NAME","SITE", "DATE_","REEF_ZONE","DEPTH_BIN","LATITUDE","LONGITUDE", "DEPTH","HARD_CORAL","MA","CCA","SAND","OTHER_BENTHIC","ComplexityValue","MEAN_SH","SD_SH_DIFF","MAX_HEIGHT", "nCounts","nReps","APVI","LUBO","Dasyatidae")]
View(wsda)
save(wsda, file="D:/CRED/data requests/species pooled by region all years/TMPwsd.Rdata")
save(data.cols, file="D:/CRED/data requests/species pooled by region all years/TMPdata.cols.Rdata")
save(sectors, file="D:/CRED/data requests/species pooled by region all years/TMPsectors.Rdata")  # save cleaned up sectors file
load("TMPsectors.Rdata")
load("TMPwsd.Rdata")
load("TMPdata.cols.Rdata")
getwd()
load("D:/CRED/data requests/species pooled by region all years/TMPwsd.Rdata")
load("D:/CRED/data requests/species pooled by region all years/TMPdata.cols.Rdata")
wsd<-wsda
## check wwhether we have ISLANDS that arent in the sectors file
setdiff(unique(wsd$ISLAND),unique(sectors$ISLAND))
#set all Backreef to a single DEPTH_ZONE ("All")
levels(wsd$DEPTH_BIN)<-c(levels(wsd$DEPTH_BIN), "All")
wsd[wsd$REEF_ZONE=="Backreef",]$DEPTH_BIN<-"All"
sectors[sectors$REEF_ZONE=="Backreef",]$DEPTH_BIN<-"All"
wsd$DEPTH_BIN<-as.character(wsd$DEPTH_BIN)# won't change value to "All" if it is a factor
wsd[wsd$ISLAND=="Rose" & wsd$REEF_ZONE=="Lagoon",]$DEPTH_BIN<-"All"
sectors[sectors$ISLAND=="Rose" & sectors$REEF_ZONE=="Lagoon",]$DEPTH_BIN<-"All"
wsd$DEPTH_BIN<-as.factor(wsd$DEPTH_BIN)# change back to factor
wsd$STRATA<-paste(substring(wsd$REEF_ZONE,1,1), substring(wsd$DEPTH_BIN,1,1), sep="")
sectors$STRATA<-paste(substring(sectors$REEF_ZONE,1,1), substring(sectors$DEPTH_BIN,1,1), sep="")
## TREAT GUGUAN, ALAMAGAN, SARIGAN AS ONE ISLAND  (REALLY ONE BASE REPORTING UNIT .. BUT SIMPLER TO STICK TO 'ISLAND')
SGA<-c("Guguan", "Alamagan", "Sarigan")
levels(wsd$ISLAND)<-c(levels(wsd$ISLAND), "AGS")
wsd[wsd$ISLAND %in% SGA,]$ISLAND<-"AGS"
sectors[sectors$ISLAND %in% SGA,]$ISLAND<-"AGS"
levels(wsd$ANALYSIS_YEAR)<-c(levels(wsd$ANALYSIS_YEAR), "2016on")
wsd[wsd$REGION %in% c("MHI", "NWHI") & wsd$OBS_YEAR==2016,]$ANALYSIS_YEAR<-"2016on"
wsd[wsd$REGION %in% c("MHI", "NWHI") & wsd$OBS_YEAR %in% seq(2010,2012),]$ANALYSIS_YEAR<-"2010-12"
wsd[wsd$REGION %in% c("MHI", "NWHI") & wsd$OBS_YEAR %in% seq(2013,2015),]$ANALYSIS_YEAR<-"2013-15"
## generate a complete list of all ANALYSIS STRATA and their size
SCHEMES<-c("RAMP_BASIC", "MARI2011", "MARI2014", "TUT10_12", "AS_SANCTUARY")
for(i in 1:length(SCHEMES)){
tmp2<-sectors[,c("SEC_NAME", SCHEMES[i])]
tmp2$SCHEME<-SCHEMES[i]
names(tmp2)<- c("SEC_NAME", "ANALYSIS_SEC", "ANALYSIS_SCHEME")
tmp<-aggregate(sectors$AREA_HA, sectors[,c(SCHEMES[i], "STRATA")], sum)
tmp$SCHEME<-SCHEMES[i]
names(tmp)<-c("ANALYSIS_SEC", "STRATA", "AREA_HA", "ANALYSIS_SCHEME")
if(i==1){
st<-tmp
as<-tmp2
} else {
st<-rbind(st, tmp)
as<-rbind(as, tmp2)
}
}
as$TMP<-1
as<-aggregate(as$TMP, by=as[,c("SEC_NAME", "ANALYSIS_SCHEME", "ANALYSIS_SEC")], length)
as$x<-NULL
wsd<-merge(wsd, as, by=c("SEC_NAME", "ANALYSIS_SCHEME"), all.x=T)  # add ANALYSISS_SCHEME for tthis sector and sceheme combination
unique(wsd[is.na(wsd$ANALYSIS_SCHEME), c("ISLAND", "ANALYSIS_SEC", "SEC_NAME", "OBS_YEAR", "ANALYSIS_YEAR", "ANALYSIS_SCHEME", "STRATA")])
cast(st, ANALYSIS_SEC ~ ANALYSIS_SCHEME, value="AREA_HA", sum)
wsd<-merge(wsd, st, by=c("ANALYSIS_SCHEME", "ANALYSIS_SEC", "STRATA"), all.x=T)
#check if some are missing an AREA_HA .. which means that they didnt get into the stratification scheme properly
unique(wsd[is.na(wsd$AREA_HA), c("ISLAND", "ANALYSIS_SEC", "SEC_NAME", "OBS_YEAR", "ANALYSIS_YEAR", "ANALYSIS_SCHEME", "STRATA")])
#NOW CHECK HOW MANY REPS WE HAVE PER STRATA
a<-cast(wsd, REGION + ANALYSIS_SCHEME + ISLAND + ANALYSIS_SEC + ANALYSIS_YEAR ~ STRATA, value="AREA_HA", length); a
SPATIAL_POOLING_BASE<-c("REGION", "ISLAND", "ANALYSIS_SEC", "REEF_ZONE", "STRATA")
ADDITIONAL_POOLING_BY<-c("METHOD", "ANALYSIS_YEAR")                                    # additional fields that we
#generate within strata means and vars
POOLING_LEVEL<-c(SPATIAL_POOLING_BASE, ADDITIONAL_POOLING_BY)
dps<-Calc_PerStrata(wsd, data.cols, c(POOLING_LEVEL, "AREA_HA"))
#save(dps,file="tmp REA per strata.RData")
head(dps$Mean)
source("D:/CRED/fish_team_R/fish-paste/lib/Islandwide Mean&Variance Functions.R")
### CALCULATE MEAN AND VARIANCE WITHIN STRATA ###
SPATIAL_POOLING_BASE<-c("REGION", "ISLAND", "ANALYSIS_SEC", "REEF_ZONE", "STRATA")
ADDITIONAL_POOLING_BY<-c("METHOD", "ANALYSIS_YEAR")                                    # additional fields that we want to break data at, but which do not relate to physical areas (eg survey year or method)
#generate within strata means and vars
POOLING_LEVEL<-c(SPATIAL_POOLING_BASE, ADDITIONAL_POOLING_BY)
dps<-Calc_PerStrata(wsd, data.cols, c(POOLING_LEVEL, "AREA_HA"))
#save(dps,file="tmp REA per strata.RData")
head(dps$Mean)
data.cols
data.cols<-c("SITEVISITID","METHOD","OBS_YEAR","REGION","REGION_NAME","ISLAND","ANALYSIS_SCHEME","ANALYSIS_YEAR","SEC_NAME","SITE", "DATE_","REEF_ZONE","DEPTH_BIN","LATITUDE","LONGITUDE", "DEPTH","HARD_CORAL","MA","CCA","SAND","OTHER_BENTHIC","ComplexityValue","MEAN_SH","SD_SH_DIFF","MAX_HEIGHT", "nCounts","nReps","APVI","LUBO","Dasyatidae")
dps<-Calc_PerStrata(wsd, data.cols, c(POOLING_LEVEL, "AREA_HA"))
#save(dps,file="tmp REA per strata.RData")
head(dps$Mean)
rm(list=ls())
library(gdata)             # needed for drop_levels()
library(reshape)           # reshape library inclues the cast() function used below
# set working directory to fish-paste
setwd("D:/CRED/fish_team_R/fish-paste")
#LOAD LIBRARY FUNCTIONS ...
source("lib/core_functions.R")
source("lib/fish_team_functions.R")
#source("lib/Islandwide Mean&Variance Functions.R")
# get strata and sectors data data - NB - the data in the raw file should be checked and updated
sectors<-read.csv("data/Sectors-Strata-Areas.csv", stringsAsFactors=FALSE)
# load site master to merge with sector names
sm<-read.csv("data/SURVEY MASTER.csv")
sm$SITE<-SiteNumLeadingZeros(sm$SITE)
## LOAD AND CLEAN fish data
load("data/ALL_REA_FISH_RAW.rdata")
x<-df
# clean up the data to only fields we currently use
DATA_COLS<-c("SITEVISITID", "METHOD", "DATE_", "OBS_YEAR",  "SITE", "REEF_ZONE",  "DEPTH_BIN",  "ISLAND", "LATITUDE",  "LONGITUDE",  "REGION" , "REGION_NAME", "SECTOR", "SPECIAL_AREA", "EXCLUDE_FLAG", "TRAINING_YN",
"REP",  "REPLICATEID", "DIVER", "HABITAT_CODE", "DEPTH",
"HARD_CORAL", "MA",  "TA",  "CCA",  "SAND",  "SOFT_CORAL", "CLAM" , "SPONGE", "CORALLIMORPH", "CYANO", "TUNICATE", "ZOANTHID" , "OTHER", "OTHER_TYPE",
"SPECIES", "COUNT", "SIZE_", "OBS_TYPE",
"COMPLEXITY", "SUBSTRATE_HEIGHT_0", "SUBSTRATE_HEIGHT_20", "SUBSTRATE_HEIGHT_50", "SUBSTRATE_HEIGHT_100", "SUBSTRATE_HEIGHT_150", "MAX_HEIGHT", "VISIBILITY",
"SCIENTIFIC_NAME",  "TAXONNAME", "COMMONNAME", "GENUS", "FAMILY" , "COMMONFAMILYALL", "LMAX", "LW_A",  "LW_B",  "LENGTH_CONVERSION_FACTOR", "TROPHIC", "TROPHIC_MONREP")
head(x[,DATA_COLS])
x<-x[,DATA_COLS]
## Update SITE to have three numeric digits (eg OAH-01 becomes OAH-001)
x$SITE<-SiteNumLeadingZeros(x$SITE)
x[is.na(x$TRAINING_YN),]$TRAINING_YN<-FALSE   # Training flag of NA is equivalent to a FALSE .. as none of the older data was 'training data'
x<-subset(x, x$TRAINING_YN==FALSE)
x<-subset(x, x$EXCLUDE_FLAG==0, drop=TRUE)
x<-subset(x, x$METHOD %in% c("nSPC", "nSPC-CCR"), drop=TRUE)
#x<-subset(x, x$OBS_YEAR >2008, drop=TRUE)
x<-subset(x, x$OBS_TYPE %in% c("U","I","N", "F", "T", "P"))  # note this includes all the data .. wlll need to add filtering to the scripts that analyse the data
#add SURVEY MASTER information to x
x<-merge(x, sm[,c("SITEVISITID", "SEC_NAME", "ANALYSIS_YEAR", "ANALYSIS_SCHEME")], by=c("SITEVISITID"), all.x=TRUE)
#CHECK THAT all ANALYSIS_SCHEMES are present in the site_master file)
idw<-x[is.na(x$ANALYSIS_SCHEME)  & x$METHOD=="nSPC", c("REGION", "SITE","OBS_YEAR", "METHOD"),]
if(dim(idw)[1]>0) {cat("nSPC sites with MISSING ANALYSIS_SCHEME")}   # should be 0
we get standardized complexity metrics (mean hieght, mean height variability, max-height)
sh_out<-CalcMeanSHMeanSHDiff(x)
x$MEAN_SH<-sh_out[[1]]
x$SD_SH_DIFF<-sh_out[[3]]
# remove the component SUBSTRATE_HEIGHT fields
x<-x[, setdiff(names(x),c("SUBSTRATE_HEIGHT_0", "SUBSTRATE_HEIGHT_20", "SUBSTRATE_HEIGHT_50", "SUBSTRATE_HEIGHT_100", "SUBSTRATE_HEIGHT_150"))]
############################################################################################
x<-droplevels(x)
sh_out<-CalcMeanSHMeanSHDiff(x)
x$MEAN_SH<-sh_out[[1]]
x$SD_SH_DIFF<-sh_out[[3]]
# remove the component SUBSTRATE_HEIGHT fields
x<-x[, setdiff(names(x),c("SUBSTRATE_HEIGHT_0", "SUBSTRATE_HEIGHT_20", "SUBSTRATE_HEIGHT_50", "SUBSTRATE_HEIGHT_100", "SUBSTRATE_HEIGHT_150"))]
############################################################################################
x<-droplevels(x)
#convert COMPLEXITY to a numeric field ###
x$COMPLEXITY<-as.vector(toupper(x$COMPLEXITY))
x[is.na(x$COMPLEXITY),"COMPLEXITY"]<-"UNKNOWN"
COMPLEXITY_VALUES<-toupper(c("Low", "Med-Low", "Med", "Med-Hi", "Hi", "Very-Hi"))
x$ComplexityValue<-NaN
for (i in 1:length(COMPLEXITY_VALUES)){
if(COMPLEXITY_VALUES[i] %in% x$COMPLEXITY){
x[x$COMPLEXITY==COMPLEXITY_VALUES[i],]$ComplexityValue<-i
}
}
tmp.lev<-levels(x$HABITAT_CODE); head(tmp.lev)
levels(x$HABITAT_CODE)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$SCIENTIFIC_NAME); head(tmp.lev)
levels(x$SCIENTIFIC_NAME)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$COMMONNAME); head(tmp.lev)
levels(x$COMMONNAME)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$GENUS); head(tmp.lev)
levels(x$GENUS)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$FAMILY); head(tmp.lev)
levels(x$FAMILY)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$COMMONFAMILYALL); head(tmp.lev)
levels(x$COMMONFAMILYALL)<-c(tmp.lev, "UNKNOWN")
tmp.lev<-levels(x$TROPHIC_MONREP); head(tmp.lev)
levels(x$TROPHIC_MONREP)<-c(tmp.lev, "UNKNOWN")
x[is.na(x$HABITAT_CODE),"HABITAT_CODE"]<-"UNKNOWN"
x[is.na(x$SCIENTIFIC_NAME),"SCIENTIFIC_NAME"]<-"UNKNOWN"
x[is.na(x$COMMONNAME),"COMMONNAME"]<-"UNKNOWN"
x[is.na(x$GENUS),"GENUS"]<-"UNKNOWN"
x[is.na(x$FAMILY),"FAMILY"]<-"UNKNOWN"
x[is.na(x$COMMONFAMILYALL),"COMMONFAMILYALL"]<-"UNKNOWN"
x[is.na(x$TROPHIC_MONREP),"TROPHIC_MONREP"]<-"UNKNOWN"
x[is.na(x$COUNT),]$COUNT<-0
x[is.na(x$SIZE_),]$SIZE_<-0
###x[is.na(x$LMAX),]$LMAX<-999
## separate out the north and south marianas
## separate out the north and south marianas
levels(x$REGION)<-c(levels(x$REGION), "S.MARIAN", "N.MARIAN")
x[x$ISLAND %in% c("Guam", "Rota", "Aguijan", "Tinian", "Saipan"),]$REGION<-"S.MARIAN"
x[x$ISLAND %in% c("Alamagan","Guguan","Sarigan","Pagan", "Agrihan", "Asuncion", "Maug", "Farallon de Pajaros"),]$REGION<-"N.MARIAN"
sectors[sectors$ISLAND %in% c("Guam", "Rota", "Aguijan", "Tinian", "Saipan"),]$REGION<-"S.MARIAN"
sectors[sectors$ISLAND %in% c("Alamagan","Guguan","Sarigan","Pagan", "Agrihan", "Asuncion", "Maug", "Farallon de Pajaros"),]$REGION<-"N.MARIAN"
sectors<-droplevels(sectors)
#save(sectors, file="TMPsectors.Rdata")  # save cleaned up sectors file
###NEED TO SET VISIBILITY to -9999 when its NA
### NOTE THAT NWHI 2012 has VISIBLITY OF NA
unique(x[is.na(x$VISIBILITY),c("REGION", "OBS_YEAR")])
x[is.na(x$VISIBILITY),]$VISIBILITY<- -999
#x[x$VISIBILITY>30,]$VISIBILITY<- 30
x[x$SITE=="GUA-01310",]$LATITUDE<-13.24173
x[x$SITE=="GUA-01310",]$LONGITUDE<-144.70428
x<-droplevels(x)
#BENTHOS DOES NOT ALWAYS SUM TO 100% .. THIS IS A (LONG-LIVED!) TEMP FIX .. PROBABLY BETTER TO FIX THIS INSIDE ORACLE
BENTHIC_FIELDS<-c("HARD_CORAL", "SOFT_CORAL", "MA", "CCA", "TA", "SAND", "CYANO", "CLAM", "CORALLIMORPH", "ZOANTHID", "TUNICATE", "SPONGE", "OTHER")
UNIQUE_ROUND<-c("REGION", "OBS_YEAR", "METHOD")
round_table<-Aggregate_InputTable(x, UNIQUE_ROUND)
x$countBD<-apply(x[,BENTHIC_FIELDS], 1, function(xx) length(which(!is.na(xx))))  #IDW 10-22-2013 checking for situation where there is NO benthic data at all
for(i in 1:dim(round_table)[1])
{
if(round_table[i,"METHOD"] %in% c("nSPC", "nSPC-CCR"))
{
tmp_data<-x[x$OBS_YEAR==round_table[i,"OBS_YEAR"] & x$METHOD==round_table[i,"METHOD"] & x$REGION==round_table[i,"REGION"],]
#go through BENTHIC_FIELDS, checking whether there are some NAs and some data values
for(j in 1:length(BENTHIC_FIELDS))
{
## IF there are both non NAs and NAs
if(length(tmp_data[!is.na(tmp_data[,BENTHIC_FIELDS[j]]),BENTHIC_FIELDS[j]]) > 0
& length(tmp_data[is.na(tmp_data[,BENTHIC_FIELDS[j]]),BENTHIC_FIELDS[j]]) > 0)
{
#set all NAs of that field to 0
tmp_data[is.na(tmp_data[,BENTHIC_FIELDS[j]]),BENTHIC_FIELDS[j]]<-0
#now rewrite the benthic fields with NAs converted to zeros
x[x$OBS_YEAR==round_table[i,"OBS_YEAR"] & x$METHOD==round_table[i,"METHOD"] & x$REGION==round_table[i,"REGION"],BENTHIC_FIELDS[j]]<-tmp_data[,BENTHIC_FIELDS[j]]
}
}
}
}
# now reset zeros to NAs for all records where there was NO benthic data at all
x[x$countBD==0,BENTHIC_FIELDS]<-NA
wd<-droplevels(x)
library(gdata)             # needed for drop_levels()
library(reshape)           # reshape library inclues the cast() function used below
#wd<-subset(wd,wd$ISLAND == "Jarvis")
#wd<-subset(wd,wd$OBS_YEAR >=2015)
wd<-subset(wd,wd$SPECIES == "APVI"|wd$SPECIES=="LUBO"|wd$FAMILY=="Dasyatidae")
wd<-droplevels(wd)
#base information about the survey - field names should match those in input file (obviously!)
UNIQUE_SURVEY<-c("SITEVISITID","METHOD")
UNIQUE_REP<-c(UNIQUE_SURVEY, "REP")
UNIQUE_COUNT<-c(UNIQUE_REP, "REPLICATEID")
#get base survey info, calculate average depth+complexity+so on
SURVEY_INFO<-c("OBS_YEAR", "REGION", "REGION_NAME", "ISLAND", "ANALYSIS_SCHEME", "ANALYSIS_YEAR", "SEC_NAME", "SITE", "DATE_", "REEF_ZONE", "DEPTH_BIN", "LATITUDE", "LONGITUDE", "SITEVISITID", "METHOD")
survey_table<-Aggregate_InputTable(wd, SURVEY_INFO)
OTHER_BENTHIC<-c("CLAM", "CORALLIMORPH", "ZOANTHID", "TUNICATE", "SPONGE", "TA", "CYANO", "OTHER", "SOFT_CORAL")
wd$OTHER_BENTHIC<-rowSums(wd[,OTHER_BENTHIC],na.rm=T)
SURVEY_SITE_DATA<-c("DEPTH", "HARD_CORAL", "MA", "CCA", "SAND", "OTHER_BENTHIC", "ComplexityValue", "MEAN_SH", "SD_SH_DIFF", "MAX_HEIGHT")
# Generate a data frame with all benthic and site level information for each survey
survey_est_benthos<-Calc_Site_nSurveysArea(wd, UNIQUE_SURVEY, UNIQUE_REP, UNIQUE_COUNT, SURVEY_SITE_DATA)   #Calc_Site_nSurveysArea deals better with situations where one REP has benthic data and other doesnt.
surveys<-merge(survey_table, survey_est_benthos, by=UNIQUE_SURVEY)
#Pull all species information into a separate df, for possible later use ..
FISH_SPECIES_FIELDS<-c("SPECIES","TAXONNAME", "FAMILY", "COMMONFAMILYALL", "TROPHIC_MONREP", "LW_A", "LW_B", "LENGTH_CONVERSION_FACTOR")
species_table<-Aggregate_InputTable(wd, FISH_SPECIES_FIELDS)
# GENERATE SUMMARY METRICS --------------------------------------------------
#r1<-Calc_Site_Bio(wd, "TROPHIC"); trophic.cols<-names(r1[3:dim(r1)[2]])
#r2a<-Calc_Site_Abund(wd, "SPECIES"); species.cols<-levels(species_table$SPECIES)
r2b<-Calc_Site_Bio(wd, "SPECIES"); species.cols<-levels(species_table$SPECIES)
#r3<-Calc_Site_Bio_By_SizeClass(wd, c(0,20,50,Inf)); size.cols<-names(r4b)[3:dim(r4b)[2]]
#r4<-Modified_Site_Species_Richness(wd)
# to calculate mean fish length per site
#r5<-Calc_Site_MeanLength(wd,min_size=0.4)
r6<-Calc_Site_Bio(wd, "FAMILY");family.cols<-names(r6[3:dim(r6)[2]])
#Merge Site Data and Count Data Per Site Per Grouping Variable (e.g. Species, Tropic_MonRep, Family)
wsd<-merge(surveys,r2b,by=UNIQUE_SURVEY)
wsd$TotFish<-rowSums(wsd[,trophic.cols])
#wsd$TotFish<-rowSums(wsd[,trophic.cols])
data.cols<-c(trophic.cols, SURVEY_SITE_DATA)
colnames(wsd)
wsd<-merge(wsd,r6,by=UNIQUE_SURVEY)
colnames(wsd)
# data.cols<-c(data.cols, species.cols)
data.cols<-c(data.cols,family.cols)
