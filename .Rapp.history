Calc_Site_MeanLength<-function(x, min_size=1){  #
	# function assumes that x is a data frame with at least the columns/elements listed in base_cols, plus the field_of_interest, in this case CommonFamily#
	# function returns a data frame with Site_VisitID, Method, and mean site biomass(gm2) per each value of the field_of_interest (hard wired as CommonFamily for now!)#
	#Base unit will be the entire survey#
	base_cols=c("SITEVISITID", "METHOD") #
	pool_cols<-c(base_cols, "SIZE_")                          #
	#set count to zero for all sizes smaller than min size#
#	x[x$SIZE_< (min_size),]$COUNT<-0#
	#sum total number offishes per SIZE_#
	y<-aggregate(x$COUNT,by=x[,pool_cols], sum)#
	names(y)<-c(pool_cols, "COUNT")#
	y$CS<-y$COUNT*y$SIZE_#
	#now format this more or less as a crosstab, with field of interest as column variable#
	y<-aggregate(y[,c("COUNT", "CS")],by=y[,base_cols], sum)#
	y$MEAN_SIZE<-y$CS/y$COUNT#
	return(y[,c(base_cols, "MEAN_SIZE")])#
} # end Calc_Site_MeanLength
load("/Users/adel.heenan/Documents/pRojects/exploratory_ideas/sigmoidal_cumulative_biomass_curves/fish-paste/data/MONREPdata_pooled_is_yr_RZ.rdata")
ls()
head(data_pooled_is_yr)
names(data_pooled_is_yr)
names(data_pooled_is_yr$Mean)
load("/Users/adel.heenan/Documents/pRojects/exploratory_ideas/sigmoidal_cumulative_biomass_curves/fish-paste/data/islandbiophys_data_used_herbivore_analysis.RData")
ls()
head(ils)
8.5*100
runApp("~/Documents/shiny_examples/test_qc_3/")
library(Shiny)
library("Shiny")
library("shiny")
runApp("~/Documents/shiny_examples/test_qc_3/")
load("data/QC_data_for_shiny.Rdata")
runApp("~/Documents/shiny_examples/test_qc_3/")
load("/Users/adel.heenan/Documents/data_requests/jeff_maynard_tom_oliver/fish-paste/data/site_all_fishes_abundancegm2.Rdata")
ls()
head(wsd)
load("/Users/adel.heenan/Documents/data_requests/jeff_maynard_tom_oliver/fish-paste/data/site_all_fishes_abundancegm2.Rdata")
q()
load("/Users/adel.heenan/Documents/cruising/maramp 2017/fish-paste/data/ALL_REA_FISH_RAW_M17.Rdata")
ls()
summary(df)
table(df$ISLAND, df$OBS_YEAR)
rm(list=ls())#
#
library(gdata)             # needed for drop_levels()#
library(reshape)           # reshape library inclues the cast() function used below#
library(splitstackshape)
getwd()
q()
load('~/Downloads/All Islands data_pooled_is FRF CAPPED.rdata')
ls()
head(data_pooled_is)
load('~/Downloads/Capping Info ALL Fish.Rdata')
ls()
head(capping_info)
load('~/Downloads/All Islands data_pooled_is FRF CAPPED (1).rdata')
ls()
rm(list=ls())
load('~/Downloads/All Islands data_pooled_is FRF CAPPED (1).rdata')
ls()
head(data_pooled_is)
setwd("~/Documents/GitHub/scientific_data_descriptor_spc")#
rm(list=ls())#
library(gdata)             # needed for drop_levels()#
library(reshape)           # reshape library inclues the cast() function used below#
#
#LOAD LIBRARY FUNCTIONS ... #
source("lib/fish_team_functions.R")#
#source("lib/Islandwide Mean&Variance Functions.R")#
#
# get strata and sectors data data - NB - the data in the raw file should be checked and updated#
sectors<-read.csv("data/Sectors-Strata-Areas2016.csv", stringsAsFactors=FALSE)#
# load site master to merge with sector names#
site_master<-read.csv("data/SITE MASTER2016.csv")#
site_master$SITE<-SiteNumLeadingZeros(site_master$SITE)#
#
## LOAD AND CLEAN fish data#
load("data/ALL_REA_FISH_RAW.rdata")#
x<-df#
#
names(x)#
#
## first steps of tidying strip out data not to be used#
#
x[is.na(x$TRAINING_YN),]$TRAINING_YN<-FALSE   # Training flag of NA is equivalent to a FALSE .. as none of the older data was 'training data'#
x<-subset(x, x$TRAINING_YN==FALSE)#
x<-subset(x, x$OBS_YEAR > 2009)#
x<-subset(x, x$METHOD %in% c("nSPC"), drop=TRUE) # remove the ccr surveys
levels(x$DIVER)#
#
length(levels(x$DIVER))#
set.seed(123) ## to give divers the same code#
a<-floor(runif(96, min=101, max=999))#
a<-paste("D_",a, sep="")#
diver_codes<-cbind(levels(x$DIVER), a)#
#
write.csv(diver_codes, file="data/diver_codes_to_numbers.csv")#
#
levels(x$DIVER)<-a#
x<-droplevels(x)
DATA_COLS<-c("REGION","REGION_NAME", "ISLAND","SITE","LATITUDE",                  "LONGITUDE","REEF_ZONE","DEPTH_BIN","SITEVISITID","DATE_","OBS_YEAR","DIVER","REPLICATEID","REP","METHOD","DEPTH","HARD_CORAL","MA","CCA","TA","SAND","TUNICATE","ZOANTHID","CORALLIMORPH"            ,"CLAM","CYANO","HABITAT_CODE","COMPLEXITY","VISIBILITY","SLOPE_MIN_DEPTH","SLOPE_MAX_DEPTH","SUBSTRATE_HEIGHT_0","SUBSTRATE_HEIGHT_20","SUBSTRATE_HEIGHT_50","SUBSTRATE_HEIGHT_100","SUBSTRATE_HEIGHT_150","MAX_HEIGHT","URCHIN_DACOR","BORING_URCHIN_DACOR","SPECIES","TAXONNAME","COMMONFAMILYALL","TROPHIC_MONREP","LW_A","LW_B","LMAX", "LENGTH_CONVERSION_FACTOR","COUNT","SIZE_","OBS_TYPE", "OBS_DESC")
setdiff(names(x), DATA_COLS)
head(x[,DATA_COLS])
x<-x[,DATA_COLS]
x<-x[,!x$DEPTH]
x<-x[,-x$DEPTH]
x<-x[,-x$DEPTH]
x<-x[,-!("DEPTH"]
x<-x[,-!("DEPTH")]
setwd("~/Documents/GitHub/scientific_data_descriptor_spc")#
rm(list=ls())#
library(gdata)             # needed for drop_levels()#
library(reshape)           # reshape library inclues the cast() function used below#
#
#LOAD LIBRARY FUNCTIONS ... #
source("lib/fish_team_functions.R")#
#source("lib/Islandwide Mean&Variance Functions.R")#
#
# get strata and sectors data data - NB - the data in the raw file should be checked and updated#
sectors<-read.csv("data/Sectors-Strata-Areas2016.csv", stringsAsFactors=FALSE)#
# load site master to merge with sector names#
site_master<-read.csv("data/SITE MASTER2016.csv")#
site_master$SITE<-SiteNumLeadingZeros(site_master$SITE)#
#
## LOAD AND CLEAN fish data#
load("data/ALL_REA_FISH_RAW.rdata")#
x<-df#
#
names(x)#
#
## first steps of tidying strip out data not to be used#
#
x[is.na(x$TRAINING_YN),]$TRAINING_YN<-FALSE   # Training flag of NA is equivalent to a FALSE .. as none of the older data was 'training data'#
x<-subset(x, x$TRAINING_YN==FALSE)#
x<-subset(x, x$OBS_YEAR > 2009)#
x<-subset(x, x$METHOD %in% c("nSPC"), drop=TRUE) # remove the ccr surveys#
## this works fine for a one off data dump - but if we want continuity across datasets, as we complete more survey rounds, we might want to change this / have a master diver code file that new divers are added to - as the method below will change the code per diver when new names are added#
levels(x$DIVER)#
#
length(levels(x$DIVER))#
set.seed(123) ## to give divers the same code#
a<-floor(runif(96, min=101, max=999))#
a<-paste("D_",a, sep="")#
diver_codes<-cbind(levels(x$DIVER), a)#
#
write.csv(diver_codes, file="data/diver_codes_to_numbers.csv")#
#
levels(x$DIVER)<-a#
x<-droplevels(x)#
#
## standardizing names between the data file we share from here, the archived data and the data descriptor#
#
x$DEPTH_M<-x$DEPTH
x$DEPTH_M<-x$DEPTH#
x$MIN_DEPTH_M<-x$SLOPE_MIN_DEPTH#
x$MAX_DEPTH_M<-x$SLOPE_MAX_DEPTH
x$VISIBILITY_M<-x$VISIBILITY
table(x$CURRENT_STRENGTH, x$OBS_YEAR)
summary(x$CURRENT_STRENGTH)
head(which(is.na(x$CURRENT_STRENGTH)))
head(x)
head(x[,1:5])
head(x[,1:10])
head(x[,10:15])
head(x[,10:20])
head(x[,18:22])
head(x[,18:26])
head(x[,c(18,3,7,26:28])
head(x[,c(18,3,7,26:28)])
head(x[,c(18,3,7,26:30)])
head(x[,c(18,3,7,26:36)])
head(x[,c(18,3,7,36:46)])
head(x[,c(18,3,7,46:56)])
head(x[,c(18,3,7,52:56)])
head(x[,c(18,3,7,48:56)])
head(x[,c(18,3,7,48:51)])
tmp<-x[,c(18,3,7,48:51)]
table(tmp$CURRENT_STRENGTH, tmp$OBS_YEAR)
ia.na(tmp$CURRENT_STRENGTH)
is.na(tmp$CURRENT_STRENGTH)
head(tmp[is.na(tmp$CURRENT_STRENGTH),]
head(tmp[is.na(tmp$CURRENT_STRENGTH),])
tmp[is.na(tmp$CURRENT_STRENGTH),]
tmptmp<-tmp[is.na(tmp$CURRENT_STRENGTH),]
droplevels(tmptmp)
tmptmp<-droplevels(tmptmp)
table(tmptmp$CURRENT_STRENGTH, tmptmp$OBS_YEAR)
summary(tmptmp)
table(tmptmp$ISLAND, tmptmp$OBS_YEAR)
table(x$ISLAND, x$OBS_YEAR)
summary(x$Complexity)
setwd("~/Documents/GitHub/scientific_data_descriptor_spc")#
rm(list=ls())#
library(gdata)             # needed for drop_levels()#
library(reshape)           # reshape library inclues the cast() function used below#
#
#LOAD LIBRARY FUNCTIONS ... #
source("lib/fish_team_functions.R")#
#source("lib/Islandwide Mean&Variance Functions.R")#
#
# get strata and sectors data data - NB - the data in the raw file should be checked and updated#
sectors<-read.csv("data/Sectors-Strata-Areas2016.csv", stringsAsFactors=FALSE)#
# load site master to merge with sector names#
site_master<-read.csv("data/SITE MASTER2016.csv")#
site_master$SITE<-SiteNumLeadingZeros(site_master$SITE)#
#
## LOAD AND CLEAN fish data#
load("data/ALL_REA_FISH_RAW.rdata")#
x<-df#
#
names(x)#
#
## first steps of tidying strip out data not to be used#
#
x[is.na(x$TRAINING_YN),]$TRAINING_YN<-FALSE   # Training flag of NA is equivalent to a FALSE .. as none of the older data was 'training data'#
x<-subset(x, x$TRAINING_YN==FALSE)#
x<-subset(x, x$OBS_YEAR > 2009)#
x<-subset(x, x$METHOD %in% c("nSPC"), drop=TRUE) # remove the ccr surveys#
## this works fine for a one off data dump - but if we want continuity across datasets, as we complete more survey rounds, we might want to change this / have a master diver code file that new divers are added to - as the method below will change the code per diver when new names are added#
levels(x$DIVER)#
#
length(levels(x$DIVER))#
set.seed(123) ## to give divers the same code#
a<-floor(runif(96, min=101, max=999))#
a<-paste("D_",a, sep="")#
diver_codes<-cbind(levels(x$DIVER), a)#
#
write.csv(diver_codes, file="data/diver_codes_to_numbers.csv")#
#
levels(x$DIVER)<-a#
x<-droplevels(x)#
#
## standardizing names between the data file we share from here, the archived data and the data descriptor#
x$DEPTH_M<-x$DEPTH#
x$MIN_DEPTH_M<-x$SLOPE_MIN_DEPTH#
x$MAX_DEPTH_M<-x$SLOPE_MAX_DEPTH#
x$VISIBILITY_M<-x$VISIBILITY
summary(x$COMPLEXITY)
class(x$COMPLEXITY)
summary(x$MAX_HEIGHT)
table(is.na(x$MAX_HEIGHT), x$OBS_YEAR)
table(is.na(x$URCHIN_DACOR), x$OBS_YEAR)
table(is.na(x$MAX_DEPTH_M), x$OBS_YEAR)
rm(list=ls())
library(sp)#
library(rgdal)#
library(rgeos)#
library(maptools)
list.files()
list.files("data")
getwd()
setwd(~/Documents/GitHub/fish-paste)
setwd("~/Documents/GitHub/fish-paste")
list.files()
list.files("data.")
list.files("data/")
gua.tow.data<-readOGR("data/sector_mpa_shape_files/guam_sectors_2017.shp")
gua_shp<-readOGR("data/sector_mpa_shape_files/guam_sectors_2017.shp")
proj4string(gua_shp)
data@gua_shp
data(gua_shp)
str(gua_shp)
plo(gua_shp)
plot(gua_shp)
#plot(gua_shp)
gua_shp@data
load('~/Documents/GitHub/fish-paste/data/ALL_TOW_FISH_RAW.rdata')
ls()
head(df)
tow<-df
tow<-tow[,c("REGION", "ISLAND", "SEGMENTID", "CENTROIDLAT", "CENTROIDLON")]
head(tow)
names(tow)
names(tow)<-c("REGION", "ISLAND", "SEGMENTID", "LATITUDE", "LONGITUDE")
coordinates(tow)<- ~ LONGITUDE + LATITUDE
summary(tow)
tow<-tow[complete.cases(tow),]
summary(tow)
rm(list=ls())#
## sptail data libraries#
library(sp)#
library(rgdal) ## make sure GDAL and PROJ.4 libraries load successfully in message - if not try update R version#
library(rgeos)#
library(maptools)#
## #
#
#### read in shape files#
gua_shp<-readOGR("data/sector_mpa_shape_files/guam_sectors_2017.shp")#
proj4string(gua_shp)#
#plot(gua_shp)#
#
## read in site / segment lat longs#
## data has to be in format region island identifier 1 identifier 2 latitude 1 latitude 2 #
## have an if else statement if tow take these cols#
## if spc take these cols#
#
load('~/Documents/GitHub/fish-paste/data/ALL_TOW_FISH_RAW.rdata')#
#
tow<-df#
tow<-tow[,c("REGION", "ISLAND", "SEGMENTID", "CENTROIDLAT", "CENTROIDLON")]#
names(tow)<-c("REGION", "ISLAND", "SEGMENTID", "LATITUDE", "LONGITUDE")#
tow<-tow[complete.cases(tow),] ## for now stripping out missing values - awaiting proper tow corrected file#
coordinates(tow)<- ~ LONGITUDE + LATITUDE
class(tow)
proj4string(tow)
GUA_PROJ<-proj4string(gua_shp)
tmp<-split(tow)
tmp<-split(tow. by=REGION)
?split
tmp<-split(tow, tow$REGION)
str(tmp)
list_regs<-split(tow, tow$REGION)
list.files()
sam_shp<-readOGR("~/Documents/pRojects/Trophic_signature_coral_reefs/data_pre-processing/data_raw/sector_shape_files/tutuila_sectors.shp")
sam_shp<-readOGR("~/Documents/pRojects/Trophic_signature_coral_reefs/data_pre-processing/data_raw/sector_shape_files/tutuila_sectors.shp")
sam_shp<-readOGR("/Documents/pRojects/Trophic_signature_coral_reefs/data_pre-processing/data_raw/sector_shape_files/tutuila_sectors.shp")
rm(list=ls())#
## sptail data libraries#
library(sp)#
library(rgdal) ## make sure GDAL and PROJ.4 libraries load successfully in message - if not try update R version#
library(rgeos)#
library(maptools)
gua_shp<-readOGR("data/sector_mpa_shape_files/guam_sectors_2017.shp")#
GUA_PROJ<-proj4string(gua_shp)
load('~/Documents/GitHub/fish-paste/data/ALL_TOW_FISH_RAW.rdata')
tow<-df#
tow<-tow[,c("REGION", "ISLAND", "SEGMENTID", "CENTROIDLAT", "CENTROIDLON")]#
names(tow)<-c("REGION", "ISLAND", "SEGMENTID", "LATITUDE", "LONGITUDE")
list_regs<-split(tow, tow$REGION)
head(list_regs)
str(list_regs)
tmp<-list_regs[[MARIAN]]
tmp<-list_regs[[list_regs$MARIAN]]
list_regs$MARIAN
tmp<-list_regs[list_regs$MARIAN]
tmp<-list_regs["MARIAN"]
region<-MARIAN
tmp<-list_regs[region]
region<-"MARIAN"
tmp<-list_regs[region]
str(tmp)
str(tmp)
str(list_regs)
tmp<-data.frame(list_regs[region])
dim(tmp)
str(ste)
str(str)
str(tmp)
paste(region)
paste(region,".ISLAND")
paste(region,".ISLAND",sep="")
tmp$ANALYSIS_SEC<-tmp$paste(region,".ISLAND",sep="")
paste(region,".ISLAND",sep="")
head(tmp)
names(tmp)
names(tmp)<-names(tow)
head(tmp)
tmp$ANALYSIS_SEC<-tmp$ISLAND
head(tmp)
tmp2<-tmp[tmp$ISLAND == "Guam",]
tmp<-tmp[!tmp$ISLAND == "Guam",]
tmp2<-tmp2[complete.cases(tmp2),]
coordinates(tmp2)<- ~ LONGITUDE + LATITUDE
tmp2<-droplevels(tmp2)
tmp2<-tmp[tmp$ISLAND == "Guam",]
tmp<-data.frame(list_regs[region])
names(tmp)<-names(tow)
tmp$ANALYSIS_SEC<-tmp$ISLAND
tmp2<-tmp[tmp$ISLAND == "Guam",]
tmp<-tmp[!tmp$ISLAND == "Guam",]
tmp2<-tmp2[complete.cases(tmp2),] ## for now stripping out missing values - awaiting proper tow corrected file with no lat longs missing
tmp2<-droplevels(tmp2)
levels(df$REGION)
rm(list=ls())
rm(list=ls())#
## spatial data libraries#
library(sp)#
library(rgdal) ## make sure GDAL and PROJ.4 libraries load successfully in message - if not try update R version#
library(rgeos)#
library(maptools)#
## #
#
#### read in right shape files#
nameREG<-"MARIAN" ## MHI, NWHI, PRIAs, SAMOA#
if(nameREG == "MARIAN"){#
	shp<-readOGR("data/sector_mpa_shape_files/guam_sectors_2017.shp")#
}#
#
if(nameREG == "MHI"){#
	shp<-readOGR("data/sector_mpa_shape_files/guam_sectors_2017.shp")#
}#
#
if(nameREG == "SAMOA"){#
	shp<-readOGR("data/sector_mpa_shape_files/guam_sectors_2017.shp")#
}
ls()
rm(list=ls())#
## spatial data libraries#
library(sp)#
library(rgdal) ## make sure GDAL and PROJ.4 libraries load successfully in message - if not try update R version#
library(rgeos)#
library(maptools)#
## #
#
#### read in right shape files#
nameREG<-"MARIAN" ## MHI, NWHI, PRIAs, SAMOA#
if(nameREG == "MARIAN"){#
	shp<-readOGR("data/sector_mpa_shape_files/guam_sectors_2017.shp")#
	proj<-proj4string(shp)#
}#
#
if(nameREG == "MHI"){#
	shp<-readOGR("data/sector_mpa_shape_files/guam_sectors_2017.shp")#
	proj<-proj4string(shp)#
}#
#
if(nameREG == "SAMOA"){#
	shp<-readOGR("data/sector_mpa_shape_files/guam_sectors_2017.shp")#
	proj<-proj4string(shp)#
}
proj
plot(shp)
rm(list=ls())
