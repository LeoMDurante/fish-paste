```{r} 
rm(list = ls()) # clear workspace
library(tidyverse)

## LOAD: Site visit table from Oracle database that has sectors defined to each site (by Kisei)
raw<-read.csv("C:/Users/tye.kindinger/Desktop/FISH TEAM/Post-cruise workings/2022_Marianas/Site visit tables/112322_cleaned_sitevisit_CC_SEC_NAME_KT.csv") # 806 sites

# Only OCC sites with photoquads / SfM  (May want to eventually include all OCC sites into survey master- this will be a bigger lift)
raw_bf <- raw %>% filter(!(TYPE %in% c("Oceanography") & PHOTOMOSAIC_YN == "NO" & TRANSECT_PHOTOS == "NO")) # 593 sites

## QC
raw_bf %>% distinct(TYPE, PHOTOMOSAIC_YN, TRANSECT_PHOTOS, CB_ACTIVITY_YN, FISH_REA_YN) %>% arrange(TYPE)
raw_bf %>% filter(TYPE == "Fish" & FISH_REA_YN == "NO") # 5 sites (TYPE = Fish) with CTD/water samples but no Fish surveys?? 
raw_bf %>% filter(SITE %in% c("ROT-717", "ROT-742", "AGU-541", "AGU-556", "AGU-549")) %>% distinct(SITEVISITID, SITE, TYPE, CTD_ACTIVITY_YN, H2O_ACTIVITY_YN, FISH_REA_YN) 
# have unique SITEVISITIDs: REMOVE 38167, 38168, 38404, 38405,38406

raw_bf %>% filter(CB_ACTIVITY_YN == "YES") %>% distinct(TYPE)
raw_bf %>% filter(ASSOC_OCC_SITEID != "")
# carb budget fish surveys --> want all to have FISH_REA_YN = NO
raw_bf %>% filter(TYPE == "Fish" & CB_ACTIVITY_YN == "YES") 
raw_bf %>% filter(FISH_REA_YN == "YES" & CB_ACTIVITY_YN == "YES") # GUA-2587 needs to be fixed!
raw_bf %>% filter(SITE == "GUA-2587")
# has unique SITEVISITID: REMOVE 39740

# check sector names assigned to sites
raw_bf %>% distinct(SEC_NAME)
raw_bf %>% filter(grepl("TUT_", SEC_NAME)) %>% distinct(TYPE) # 18 benthic sites from Tutuila (Samoa)
raw_bf %>% filter(grepl("TUT_", SEC_NAME)) %>% distinct(EXCLUDE_FLAG) # NOT currently excluded
raw_bf %>% filter(grepl("HAW_", SEC_NAME)) # 2 Fish sites from Kona, HI
raw_bf %>% filter(grepl("HAW_", SEC_NAME)) %>% distinct(EXCLUDE_FLAG) # GOOD TO GO --> excluded already

## FIX QC ISSUES
sv <- raw_bf %>% filter(!(TYPE == "Fish" & FISH_REA_YN == "NO")) %>% # REMOVE sites that are TYPE = Fish but are only water sampling (5 sites - see list above)
  filter(!(FISH_REA_YN == "YES" & CB_ACTIVITY_YN == "YES")) %>% # REMOVE 1 CB site (not Fish REA or benthic PQ/SfM) --> CHECK if there's a way to indicate the fish surveys but indicate they're non-NCRMP w/ EXCLUDE_FLAG column
  mutate(EXCLUDE_FLAG = ifelse(grepl("TUT_", SEC_NAME), "YES", EXCLUDE_FLAG)) # indicate EXCLUDE for Samoa mission (non-NCRMP)

## CLEANUP
colnames(sv)[colnames(sv)=="MAX_DEPTH_M"]<-"new_MAX_DEPTH_M"
colnames(sv)[colnames(sv)=="MIN_DEPTH_M"]<-"new_MIN_DEPTH_M"
colnames(sv)[colnames(sv)=="LONGITUDE_LOS"]<-"LONGITUDE_LOV"
colnames(sv)[colnames(sv)=="LATITUDE_LOS"]<-"LATITUDE_LOV"

## INDICATORS OF SITE TYPE
sv.final <- sv %>% mutate(Benthic = ifelse(TYPE == "Benthic", 1, 0)) %>% 
  mutate(Fish = ifelse(TYPE == "Fish" & FISH_REA_YN == "YES", 1, 0)) %>%
  mutate(Oceanography = ifelse(TYPE == "Oceanography", 1, 0)) %>%
  mutate(CAU = ifelse(CAUS_DEPLOY_YN == "YES", 1, 0))

# Ivor's script -- additional columns in previous years
#df[df$TYPE %in% c("ARMS Only", "ARMS"),]$TYPE<-"ARMS"
#df[df$TYPE %in% c("Benthic Only", "Benthic", "Benthic & CAU"),]$TYPE<-"Benthic"
#df[df$TYPE %in% c("CAU Only", "CAU"),]$TYPE<-"CAU"
#df[df$TYPE %in% c("Oceanography Only", "Oceanography", "Oteam Only"),]$TYPE<-"Oceanography"
#df[df$TYPE %in% c("Fish Only", "Fish"),]$TYPE<-"Fish"
#df[df$TYPE %in% c("Benthic & Fish", "Both"),]$TYPE<-"Both"
 
write.csv(sv.final, "C:/Users/tye.kindinger/Desktop/FISH TEAM/Post-cruise workings/2022_Marianas/Site visit tables/12072022_cleaned_sitevisit_CC_SEC_NAME_KT_prep_TK.csv")
```

## SECTOR ASSIGNMENTS SHOULD BE QCed BY BENTHIC & FISH 
# ArcGIS: (1) load sitevisit file and plot lat/longs per site onto map (color code by depth bin); filter so only plotting fish sites!
#         (2) check sector assignments w/ sector & reef zone shapefiles: https://docs.google.com/spreadsheets/d/1ubvirPEe6gf9Ub-KEIw9bThGtvlkvzY5_09mdaUtlQo/edit?pli=1#gid=0
#         (3) compare numbers per sector-reef zone-depth bin with targeted allocation & determine sector assignments to sites on the edge of 2 sectors, etc.

## UPDATE SITEVISIT BASED ON QC
```{r} 
rm(list = ls()) # clear workspace
library(tidyverse)

## MARIANAS 2022 QC: all sector assignments look good & all sites fall into forereef areas; no reassignments needed

sv.final <- read.csv("C:/Users/tye.kindinger/Desktop/FISH TEAM/Post-cruise workings/2022_Marianas/Site visit tables/12072022_cleaned_sitevisit_CC_SEC_NAME_KT_prep_TK.csv") # 587 sites
sv.fish <- sv.final %>% filter(Fish == 1) %>% # FISH SITES ONLY --> 322 sites
  filter(SITEVISITID != 39522) # REMOVE 1 site that doesn't have any data --> survey was incomplete!
# 321 sites

# Specify EXTRA sites surveyed specifically for Guam MPA project inside Piti Bomb --> EXCLUDE_FLAG = YES ; otherwise, influence of Piti in Guam MP sector (all MPAs typically pooled per year) will be off/greater than in other years
Gmpa <- read.csv("C:/Users/tye.kindinger/Desktop/FISH TEAM/Post-cruise workings/2022_Marianas/Site visit tables/GuamMPAProject_PitiAsan_NCRMP_site_table.csv") # load GuamMPA project site indicator from Kaylyn
# FIX QC issues
Gmpa.qc <- Gmpa %>% filter(SITE != "GUA-026")  # remove 1 extra site --> erroneous (SITEVISITID = 39740)
  
# merge with SITEVISIT
sv.QC <- sv.fish %>% left_join(Gmpa.qc %>% select(SITEVISITID, SEC_NAME, ANALYSIS_SCHEME, starts_with("SPECIAL")) %>% dplyr::rename(SEC_MPA = SEC_NAME), by = c("SITEVISITID"))
sv.QC %>% select(SEC_NAME, SEC_MPA, ANALYSIS_SCHEME, starts_with("SPECIAL")) %>% distinct() %>% arrange(SEC_NAME)

# FIX QC issues
sv.clean <- sv.QC %>% 
  mutate(SEC_MPA = ifelse(SITEVISITID %in% c(38981, 39407, 39000), "GUA_ASAN", SEC_MPA)) %>% # sites missed by Kaylyn in Asan 
  mutate(ANALYSIS_SCHEME = ifelse(SEC_MPA == "GUA_ASAN", "NO SCHEME", ANALYSIS_SCHEME)) %>% # turn all Asan sites to NO SCHEME
  # indicate which sites in Asan to include as NCRMP --> optimal target #s given we had more time in Guam due to ship delays
  mutate(ANALYSIS_SCHEME = ifelse(SITEVISITID %in% c(38480, 39103, 39084, 38482, 38483, 39002, 38981, 39727, 38481, 38484, 39432, 39434, 39060), "RAMP_BASIC", ANALYSIS_SCHEME)) %>% 
  
  mutate(SPECIAL_PROJ_YN = ifelse(SEC_NAME == "GUA_PITI_BOMB" | SEC_MPA == "GUA_ASAN", -1, 0)) %>% # indicate all sites in Piti & Asan --> use in GuamMPA project
  mutate(SPECIAL_PROJ_DESCRIPTION = ifelse(SEC_NAME == "GUA_PITI_BOMB" | SEC_MPA == "GUA_ASAN", "Guam_Piti_2022", NA)) %>% 
  mutate(ANALYSIS_SCHEME = ifelse(SEC_NAME == "GUA_PITI_BOMB" & is.na(ANALYSIS_SCHEME), "NO SCHEME", ANALYSIS_SCHEME)) %>% # sites missed by Kaylyn in Piti --> NO SCHEME (non-NCRMP sites)
  mutate(ANALYSIS_SCHEME = ifelse(SITEVISITID %in% c(39433, 39520, 39102, 39504, 39083, 39105, 39101), "RAMP_BASIC", ANALYSIS_SCHEME)) # indicate additional sites in Piti to include as NCRMP --> optimal target #s given we had more time in Guam due to ship delays

# check
sv.clean %>% select(SEC_NAME, SEC_MPA, ANALYSIS_SCHEME, starts_with("SPECIAL")) %>% distinct() %>% arrange(SEC_NAME)
sv.clean %>% filter(SPECIAL_PROJ_DESCRIPTION == "Guam_Piti_2022" & ANALYSIS_SCHEME == "RAMP_BASIC") %>% group_by(SEC_NAME, DEPTH_BIN) %>% dplyr::summarise(n = n_distinct(SITEVISITID)) %>% as.data.frame() %>% arrange(SEC_NAME)
# good to go! 
#GUA_PITI_BOMB	Deep	5		
#GUA_PITI_BOMB	Mid	4		
#GUA_PITI_BOMB	Shallow	6		
#GUA_WEST_OPEN	Deep	3		
#GUA_WEST_OPEN	Mid	5		
#GUA_WEST_OPEN	Shallow	5	

  
# FINAL CLEANUP
sv.clean %>% select(SEC_NAME, ANALYSIS_SCHEME, starts_with("SPECIAL"), EXCLUDE_FLAG) %>% distinct() %>% arrange(SEC_NAME)

sv.qc.final <- sv.clean %>% select(-SEC_MPA) %>%
  # fill in remaining indicator values
  mutate(SPECIAL_PROJ_YN = ifelse(SEC_NAME == "HAW_KONA", -1, SPECIAL_PROJ_YN)) %>% # indicate all sites in 2022 HIMARC Calibration Weekend in Kona, HI (2 sites)
  mutate(SPECIAL_PROJ_DESCRIPTION = ifelse(SEC_NAME == "HAW_KONA", "HIMARC_CalibWknd_2022", SPECIAL_PROJ_DESCRIPTION)) %>% 
  mutate(ANALYSIS_SCHEME = ifelse(SEC_NAME == "HAW_KONA", "NO SCHEME", ANALYSIS_SCHEME)) %>% 
  # indicate exclusion of special project sites that aren't also part of NCRMP
  mutate(EXCLUDE_FLAG = ifelse(ANALYSIS_SCHEME %in% c("NO SCHEME"), -1, 0)) %>% # turn EXCLUDE_FLAG to -1 vs. 0 to be consistent with SURVEY MASTER (-1 = exclude)
  # fill in remaining NAs
  mutate(ANALYSIS_SCHEME = ifelse(is.na(ANALYSIS_SCHEME), "RAMP_BASIC", ANALYSIS_SCHEME)) %>%
  mutate(SPECIAL_PROJ_YN = ifelse(is.na(SPECIAL_PROJ_YN), 0, SPECIAL_PROJ_YN)) 

sv.qc.final %>% select(SEC_NAME, ANALYSIS_SCHEME, EXCLUDE_FLAG, starts_with("SPECIAL")) %>% distinct() %>% arrange(SEC_NAME)

# REMERGE with benthic sites
sv.fishQC <- sv.qc.final %>% 
  bind_rows(sv.final %>% filter(Fish == 0) %>% # 265 benthic sites
              mutate(EXCLUDE_FLAG = ifelse(EXCLUDE_FLAG == "YES", -1, 0)) %>% # turn EXCLUDE_FLAG to -1 vs. 0 to be consistent with SURVEY MASTER (-1 = exclude)
              mutate(SPECIAL_PROJ_YN = ifelse(grepl("TUT_", SEC_NAME), -1, 0))) # update special project YN for TUT sites

sv.fishQC %>% distinct(SEC_NAME, SPECIAL_PROJ_DESCRIPTION, SPECIAL_PROJ_YN, EXCLUDE_FLAG)

## SAVE
write.csv(sv.fishQC, "C:/Users/tye.kindinger/Desktop/FISH TEAM/Post-cruise workings/2022_Marianas/Site visit tables/12122022_SITEVISIT_QC_TLK.csv")

```

## PREPARE & MERGE SITEVISIT WITH SURVEY MASTER --> NOTE, used some code from Ivor's Update SurveyMaster script
```{r} 
rm(list = ls()) # clear workspace
library(tidyverse)

sv.ready <- read.csv("C:/Users/tye.kindinger/Desktop/FISH TEAM/Post-cruise workings/2022_Marianas/Site visit tables/12122022_SITEVISIT_QC_TLK.csv") %>% mutate_all(na_if,"")  # 586 sites

SM <- read.csv("C:/Users/tye.kindinger/Desktop/FISH TEAM/fish-paste/data/SURVEY MASTER.csv") # load most recent SURVEY MASTER

# compare column names with those in SURVEYMASTER
sv.ready[,order(colnames(sv.ready))] %>% names()

# MISSING FROM SITEVISIT:
# OLD_SITE, OCC_SITEID, PERM_SITE, benth, fish, arms_d, arms_r, microb, ARMS, HUMANS20, HUMANS200, TYPE = RANDOM, FIXED, Haphazard, NA, BAD HABITAT, bANALYSIS_SCHEME, ANALYSIS_YEAR, TUT2012, OTHER_AREA_GROUPING

# CHECK OCC SITE COLUMNS
sv.ready %>% distinct(ASSOC_OCC_SITEID, OCC_SITEID)
sv.ready %>% filter(!is.na(ASSOC_OCC_SITEID) & !is.na(OCC_SITEID)) # when values in both columns, they're the same SITEID

## CLEAN UP
sv.final <- sv.ready %>% 
# TRANSLATED FROM IVOR'S Update SurveyMaster SCRIPT:
  
  # EXTRACT year from date-time
  separate(DATE_, c("X_", "X_2"), sep = " ", remove = FALSE) %>% separate(X_, c("X_3", "X_4", "X_5"), sep = "/", remove = FALSE) %>% 
  mutate(OBS_YEAR = as.integer(X_5)) %>% select(-starts_with("X_")) %>% 
  # PAD site IDs with 0s as needed (5-digit numbers after dash) --> dplyr version of SiteNumLeadingZeros function in core_functions
  mutate(OLD_SITE = SITE) %>% 
  separate(SITE, c("X_", "X_2"), sep = "-", remove = FALSE) %>% mutate(X_3 = ifelse(nchar(X_2) < 5, str_pad(X_2, 5, side = "left", pad = "0"))) %>% 
  unite("SITE", X_, X_3, sep = "-", remove = TRUE) %>% select(-starts_with("X_")) %>%
  # CREATE 0-1 indicators of activities --> 0 = NO / 1 = YES (Note: columns ARMS, Benthic, CAU, Fish, Oceanography already 0-1s)
  mutate(benth = ifelse(CORAL_BELT_ADULT_YN == "YES" | CORAL_BELT_JUVENILE_YN == "YES", 1, 0)) %>% # other possible column: LPI_YN
  mutate(fish = ifelse(FISH_REA_YN == "YES", 1, 0)) %>%
#  mutate(arms_d = ifelse(ARMS_DEPLOY_YN == "YES", 1, 0)) %>%
#  mutate(arms_r = ifelse(ARMS_RECOVERED == "YES" | ARMS_RETRIEVE_YN == "YES", 1, 0)) %>%
  mutate(cau_d = ifelse(CAUS_DEPLOY_YN == "YES", 1, 0)) %>% # other possible column: CAUS_DEPLOYED
  mutate(cau_r = ifelse(CAUS_RETRIEVE_YN == "YES", 1, 0)) %>%   # other possible column: CAUS_RECOVERED
#  mutate(microb = ifelse(MICROBIAL_SAMPLE == "YES", 1, 0)) %>%
  
# TLK ADDITIONAL CLEANING
  
  # COMBINE assoc_OCC with OCC_siteID
  mutate(OCC_SITEID = ifelse(is.na(OCC_SITEID) & !is.na(ASSOC_OCC_SITEID), ASSOC_OCC_SITEID, OCC_SITEID)) %>% # NOTE: even though repeating OCC_SITEIDs, they each have a unique SITEVISITID
  # RECODE YN columns into -1-0-1 indicators
  mutate_at(vars(CLIMATE_STATION_YN, PHOTOMOSAIC_YN, TRANSECT_PHOTOS), ~ifelse(. == "YES", 0, -1)) %>% #?????
  
  # TYPE as survey site type (e.g., Haphazard, Fixed, Random, etc.) ????? 

  # REMOVE columns NOT in SurveyMaster
  select(-ASSOC_OCC_SITEID, -contains("DEPLOY"), -contains("RETRIEVE"), -contains("ACTIVITY_"), -contains("COMMENTS_"), -contains("CORAL_"), -DISTRICT, -DIVE, -FISH_REA_YN, -LOCALTIME, 
        -contains("_Z_"), -contains("OBJECTID_"), -SECTOR, -SITEDESCRIPTION, -VISIBILITY, -VISIBILITY_M)
        

## ADD LATEST SITES TO SURVEY MASTER
SM.full <- SM %>% bind_rows(sv.final %>% mutate_at(vars(SPECIAL_PROJ_YN), ~as.character(.)))

sm.final <- SM.full %>% filter(OBS_YEAR == 2022) %>% 
  # TURN NAs into 0-1 indicators
  mutate_at(vars(arms_d, arms_r, microb, ARMS), ~ifelse(is.na(.), 0, 1)) %>% 
  # COMPLETE analysis year
  mutate(ANALYSIS_YEAR = as.character(OBS_YEAR)) %>%
  # FISH --> add RAMP_BASIC scheme
  mutate(ANALYSIS_SCHEME = ifelse(is.na(ANALYSIS_SCHEME) & Fish == 1, "RAMP_BASIC", ANALYSIS_SCHEME)) %>% 

  # add back in rest of sites
  bind_rows(SM.full %>% filter(OBS_YEAR != 2022)) %>% arrange(SITEVISITID) %>%
  # reorder columns
  dplyr::relocate(SEC_NAME, REEF_ZONE, DEPTH_BIN, new_MIN_DEPTH_M, new_MAX_DEPTH_M, .after = ISLAND) %>%
  dplyr::relocate(ROUNDID, MISSIONID, .after = SITEVISITID) %>%
  dplyr::relocate(LATITUDE_SV, LONGITUDE_SV, LATITUDE_LOV, LONGITUDE_LOV, .after = OCC_SITEID) %>%
  dplyr::relocate(ANALYSIS_YEAR, .after = OBS_YEAR)


write.csv(sm.final, "C:/Users/tye.kindinger/Desktop/SM_fish_2022.csv")
```


#### 2022 FISH DATA
```{r} 
rm(list = ls()) # clear workspace
library(tidyverse)

fish <- read.csv("C:/Users/tye.kindinger/Desktop/V0_FISH_REA_MARIAN_2022.csv") # load most recent fish data --> 37,042 rows
fish %>% distinct(SITEVISITID) # 319 sites

sm <- read.csv("C:/Users/tye.kindinger/Desktop/SM_fish_2022.csv") %>% filter(OBS_YEAR == 2022 & Fish == 1)  # load most recent survey master
sm %>% distinct(SITEVISITID) # 321 sites

## QC FISH DATA based on findings above while QCing SM

# merge sm and check for sites that should be removed: 
# (1) REMOVE 5 sites that are TYPE = Fish but are only water sampling --> SITEVISITID %in% c(38167, 38168, 38404, 38405,38406) 
# (2) REMOVE 1 CB site (not Fish REA or benthic PQ/SfM) --> SITEVISITID = 39740
# (3) REMOVE 1 site that doesn't have any data (survey was incomplete) --> SITEVISITID = 39522
# (4) REMOVE 1 site that was an error (never existed) --> SITEVISITID = 39740

fish.sm <- fish %>% select(-EXCLUDE_FLAG, -DATE_) %>%  # all rows have EXCLUDE_FLAG = 0 (keep) --> use QCed exclude column from SM!
  left_join(sm %>% select(SITEVISITID, DATE_, SEC_NAME, EXCLUDE_FLAG, starts_with("SPECIAL")), by = c("SITEVISITID")) %>% # use SM DATE_ because still in number format of dates
  # CLEAN UP date formatting for merging with ongoing dataset --> POSIXct %m/%d/%Y	
  separate(DATE_, c("DATE", "X_TIME"), sep = " ", remove = FALSE) %>% mutate(DATE2 = as.POSIXct(DATE, format = "%m/%d/%Y")) %>% select(-DATE_, -DATE) %>% dplyr::rename(DATE_ = DATE2)

# checks
fish.sm %>% distinct(SEC_NAME) # HIMARC sites weren't included --> GOOD!
sm %>% left_join(fish.sm %>% distinct(SITEVISITID) %>% mutate(x = "Y"), by = c("SITEVISITID")) %>% filter(is.na(x)) # sites in SM but missing from fish data --> HIMARC sites are missing --> OK!
fish.sm %>% select(EXCLUDE_FLAG, starts_with("SPECIAL")) %>% distinct() # GuamMPA sites look good
fish.sm %>% filter(SPECIAL_PROJ_YN == "-1") %>% group_by(SEC_NAME, DEPTH_BIN, EXCLUDE_FLAG) %>% dplyr::summarise(n = n_distinct(SITEVISITID)) %>% arrange(SEC_NAME, EXCLUDE_FLAG) # GOOD!
# GUA_WEST_OPEN: deep = 3, mid = 5, shallow = 5 | GUA_PITI_BOMB: deep = 5, mid = 4, shallow = 6

fish.sm %>% filter(SITEVISITID %in% c(38167, 38168, 38404, 38405, 38406, 39740, 39522, 39740))  # specific sites that needed to be removed --> GOOD! Not included / no fish data

sm %>% filter(OBS_YEAR == 2022 & Fish == 1 & EXCLUDE_FLAG == 0) %>% distinct(SITEVISITID)  # 297 sites
fish.sm %>% filter(EXCLUDE_FLAG == 0) %>% distinct(SITEVISITID) # 297 sites
# all NCRMP sites present!

# SAVE
write.csv(fish.sm, "C:/Users/tye.kindinger/Desktop/FISH TEAM/Post-cruise workings/2022_Marianas/2022 Fish data/fishdata_2022.csv")
  
## COMBINE WITH REST OF FISH DATA
load("C:/Users/tye.kindinger/Desktop/FISH TEAM/fish-paste/data/DEFUNCT files/defunct_pre2022_ALL_REA_FISH_RAW.rdata")
df # 988,383 rows

# NAME df SO CONSISTENT WITH FISH SCRIPTS!!
df <- fish.sm %>% # 37,042 rows  
  bind_rows(df) 
# 1,025,425 rows

# SAVE
save(df, file = "C:/Users/tye.kindinger/Desktop/FISH TEAM/fish-paste/data/ALL_REA_FISH_RAW.RData")
```

